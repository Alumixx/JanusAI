Bimetric models. When negative mass replaces both dark  matter and dark energy.   Excellent agreement with observational data. Solving the problem of the primeval antimatter. Description of the radiative era. 

J.P.Petit ,  G.d’Agostini Nathalie Debergh
Manaty Research Group
_____________________________________________________________________________________________________
Keywords : negative mass, bimetric models, bigravity, very large structure, acceleration of the cosmic expansion, dark matter, dark energy, spiral structure, great repeller, negative gravitational lensing, dynamical groups, primeval antimatter, Sakharov model
_____________________________________________________________________________________________________
Abstract : 
If one tries to include negative masses in General Relativity one immediately comes up against the runaway effect, violating the principle of action-reaction. It is then necessary to consider a bimetric model. The starting point is S. Hossenfelder's model, which is mathematically correct, but incompatible with the observational data. This approach is taken up again. The field equations then make it possible to account for many observational aspects, including the acceleration of expansion, the strong gravitational lens effects in the vicinity of galaxies and clusters, and the flatness of the rotation curves. Using the dynamic group theory we show that this negative mass is a copy of classical antimatter, with negative mass. This approach, concretizing the ideas of A.Sakharov, resolves the paradox of the absence of observation of primordial antimatter. The questions remaining to be addressed are listed so that the model could pretend to be  a challenger to the mainstream ΛCDM model. 
_____________________________________________________________________________________________________

1 – Cosmology today. Questions that remain unsolved.
Fifty years ago the scientific community thought it had built a model with a high level of credibility, based on Einstein's field equation. At that time the debate among specialists centered on the choice between one of Friedmann's three models and everyone thought that the cosmological constant was either null or negligible.
It all began with the problem posed by the advance of Mercury's perihelion. Leverrier's earlier attempt at interpretation, based on a new planet he had called Vulcan, had failed. Einstein provided the solution by creating a major paradigm shift.  His model was later supported by the evidence of the gravitational lens effect that the Sun had on the light from the stars. 
The construction of unsteady solutions led to a model where the universe was expanding from a moment zero. Thus, going back in time, one must deal with conditions of temperature and pressure beyond imagination. It was therefore essential to describe the cosmic content under such conditions. 
We thus envisaged conditions where the universe was in a state of equilibrium where the synthesis of pairs of particles and antiparticles was compensated by the annihilation of these same pairs by producing photons. Under these conditions the cooling due to the expansion stopped this production of pairs, while the annihilation reactions continued. These primordial photons, corresponding to a background radiation at 2.7°, were highlighted, which gave a strong credibility to the model. 
But under these conditions the annihilation of the matter-antimatter pairs should have continued until their complete disappearance. The simple fact that we have before our eyes a universe made up of matter showed that this was not the case. A question then arose: 
What had become of this primordial antimatter, of which all attempts to bring to light proved to be failures?  

 Currently, and we insist on this point of epistemology, no scientist doubts their existence when it has not been possible to detect the presence of these particles of primordial antimatter
1 - We will bring in this article a consistent answer to this problem, including the explanation of this non-observation of primordial antimatter and describing precisely the nature of its components.
Beyond these already very impressive temperatures it was desirable to be able to provide again a description of the cosmic content. Particle accelerators thus became the tools to try to re-create these conditions in the laboratory. Particle physics developed. Not only did it make it possible to recreate this synthesis of antimatter in situ, but it constituted a dismantling of the constituents of the nuclei which culminated with the quarks model, allowing the prediction of the existence of new, unstable particles, whose fleeting presence was demonstrated by detailing the reaction products. It was then that it proved impossible to obtain direct evidence of quarks, although they are equipped with fractional electric charges. This question was resolved by assuming that these quarks in the free state, undergoing forces of attraction increasing with distance, could not persist for their existence to be demonstrated. Nevertheless, given the fertility of the model, with respect to the construction of new particles, whose existence was proven, it was imposed.   
It was nevertheless necessary to construct a description of the cosmic content for even higher temperatures. The standard particle model was then extended by creating what was called supersymmetry. 
A very large number of papers were then published in high level journals, bringing the description of superparticles, partners of the standard particles, such as photino, neutralino etc....  
But while the energies used had largely reached and exceeded the required thresholds, the existence of any of these superparticles could not be demonstrated.
For decades, many scientists tried to develop a theory that was both more comprehensive and totally different from the material that became known as string theory.
But while this movement gave rise, for decades, to the publication of innumerable articles in very high level journals, it proved incapable of producing a model of anything that would lend itself to any kind of observation.
Other problems arose. The observations made with the help of satellites showed the extraordinary homogeneity of the primitive universe, in its radiative phase. The journals published a very large number of articles tending to explain this state of affairs by a fantastic primordial inflation, due to a mysterious field of inflatons
But today scientists cannot agree on both an inflationary scenario and a precise inflaton model.
Other problems arose. At the end of the seventies, the measurement of the rotational velocities of gaseous elements in galaxies became precise enough to create a new paradox: the flatness of these curves at the galactic periphery [1] . The distribution of matter deduced from the observations did not allow to reconstruct these curves.
The scientific community then saw in such a phenomenon the undeniable proof of the existence of particles with mass, undetected.
By reversing the problem one considered that instead of deducing the rotation curves of measurements on the local density of dark matter it was decided to  deduce it from the shape of the curves.. 
- To date, in spite of the very large means implemented, no dark matter particles have been detected in experiments conducted underground, sheltered from the background noise constituted by cosmic rays, or in space, in detectors
2 – In this paper we will provide an alternative interpretation of the flatness of the rotation curves in galaxies at periphery, showing how this new model allows to reconstruct them accurately.
This problem of the flatness of the rotation curves was joined to that of the excessive velocities of galaxies in clusters, exceeding the escape velocity calculated on the mass of such clusters, deduced from the observations.
Here again the new model, implying the existence of a dark matter of unknown nature, over invoked it to account for this phenomenon by associating to the clusters a vast halo constituted by this unidentified component.
3 – In this paper we will provide an alternative interpretation of this phenomenon of galaxy overspeed in clusters. 
These anomalies concerning the rotation velocities in galaxies and the random velocities of galaxies in clusters went hand in hand with the discovery of strong gravitational lens effects, which could not be produced by the masses deduced from the observations. 
While no direct observation or experiment (evidence of neutralino in particle accelerators) has so far succeeded in highlighting these components of dark matter, the scientific community considers their existence as an established fact, undeniable insofar as their presence provides both the means to constitute these gravitational lens effects in the vicinity of clusters and galaxies, and to account for the kinematic anomalies found in the vicinity of these same objects. 
4 – In this paper we will provide an alternative interpretation of the strong gravitational lens effects in the vicinity of galaxies and clusters. 
As a reminder, we will mention the attempt to remotely modify Newton's law, proposed by the Israeli Mordechaii Milgrom [2], a theory devoid of ontological (geometrical) foundation that fails to account for both galaxy and cluster-related effects. 
Another important problem is the recent discovery of the phenomenon of the acceleration of cosmic expansion, sanctioned in 2011 by a Nobel Prize ([3], [4], [5]). But here, the Einsteinian model could provide a beginning of interpretation by reintroducing into the equation the cosmological constant Λ. This phenomenon was attributed to negative pressure. The pressure being a density of energy per unit volume, this same energy was itself negative. 
These different aspects were placed under the same label, that of a dark energy, associated with some vacuum energy, which quantum mechanics cannot account for. 
Opting for a purely phenomenological description, the current main stream model ΛCDM combines these two hypotheses: 
That of the supposed existence of a cold dark matter (animated at low speeds with respect to c).

That of the existence of this dark energy, phenomenologically taken into account by the resurgence of the cosmological constant in the field equation. 
5 – The model we propose provides an interpretation of the phenomenon of cosmic expansion acceleration which has been successfully compared with data from 700 type Ia supernovae. It specifies which cosmic elements and components are responsible for this phenomenon, unlike the model ΛCDM, which only provides a purely phenomenological reading of the process. 
Indeed, there is to date no model of dark energy, and no beginning of explanation of this phenomenon apart from the phenomenology associated with the presence of the cosmological constant, synonymous with vacuum energy. 
6 – As part of the team's work, one of the signatories of this paper, Nathalie Debergh, showed in 2018 [8] that quantum mechanics could very well produce negative energy states. 
There is no real explanation clearly justifying with a theoretical basis the lacunar structure of the observed matter, except for numerical simulation results, which show clusters and filaments.
7 – In this article we give the reason for the existence of such a lacunar structure. 
Very recently, in 2017, a very large scale mapping of the universe (a cube of one and a half billion light years on one side, giving both the distribution of matter (galaxies) and the general shape of the velocity field [7]) has revealed a new anomaly. 600 million light-years from our galaxy, the existence of a very large vacuum, where no galaxy was present, was revealed, which, given the direction of the velocities of the surrounding galaxies, evoked a powerful phenomenon of repulsion. This formation was given the name Great Repeller. 
No theoretical modeling of this phenomenon has been published in a high-level journal. At most, it has been suggested that the phenomenon could betray the presence of a gap in a uniform distribution of dark matter, which was tantamount to adding another hypothesis to a first hypothesis. There is no model describing the formation of such a gap. 
8 – The model we propose provides an interpretation of this phenomenon, implying the existence of a repulsive, unobservable cluster of negative matter at the center of this cell. This situation explains in passing the low magnitude of galaxies with strong redshift, considered in the literature as dwarf galaxies. 

 2 – A real paradigm shift. 
The proposed solutions are deliberately extraordinary and revolutionary and militate for the abandonment of the mainstream model in favor of a new, bimetric model . 
To quote a well-known aphorism, "extraordinary claims demand extraordinary evidence". It is therefore necessary to list these claims.
Some points : 
2 – Justification of the shape of the rotation curves.
3 – Explanation of overspeeds in clusters of galaxies.
4 – Explanation of the strong gravitational lens effect.
are only alternative interpretations to those provided by the hypothesis of the existence of dark, matter, which they do not invalidate. These interpretations simply show that the proposed model is not contradicted by these observations. 
But in the following points : 
 1 : Nature of primordial antimatter and explanation of its non-observation.
5 – Identification of the nature of the negative energy responsible for the acceleration of cosmic expansion.
6 – Justification of the existence of negative energy states in Quantum Mechanics.
7 – Description of the mechanism giving rise to the lacunar structure of the observed universe.
8 – Description of the object giving rise to the formation that was given the name Great Repeller.
are provided theoretical interpretations that do not emanate from the standard model ΛCDM. Precise answers are given where the standard model does not provide any. 
This paradigm shift can be summed up in a simple sentence: 
Let's introduce negative masses in the cosmological model.
Before describing how we proceeded it is essential to show why this hypothesis has not been able to emerge to date. 

2 – The runaway effect, a barrier against the introduction of negative masses.
This question of the introduction of negative masses was tackled as early as 1957 by H. Bondi [8] and then in 1989 by W. Bonnor [9]. It is important to make it clear why this causes the appearance of a phenomenon that is difficult to manage in physics, the runaway effect, if only because it violates the principle of action-reaction.  
By ignoring the non-linearity of Einstein's equation, we can schematize it by saying that in the second member is the source of the gravitational field. The equation provides a solution in the form of a single metric from which one calculates sets of geodesics, corresponding to non-zero geodesics (masses) and null geodesics (photons). The cosmological constant can be abstracted for this question. 
(1)                                                                  
The geometry associated with the presence of a mass M, represented by a sphere filled with matter of a given mass density  , is perfectly determined, both outside and inside this mass M and  can be constructed from equation (1). 
Outside this mass M, the trajectories of the control particles correspond to the external Schwarzschild metric
 (2)                                   
If this mass M is positive, the behavior of the control particles in its vicinity corresponds to an attraction, as shown in figure 1. d

 
Fig.1 : Geodesic trajectories of control masses in the vicinity of a positive mass

We consider that these geodesic trajectories are those of particles of matter but the solution does not specify the sign of the considered mass. Thus: 
- Objects with positive mass M > 0 attract indifferently the other masses, whether positive or negative
If the source mass M of the field is negative, the shape of the geodetic trajectories taken by the control masses, whether positive or negative, is shown in Figure 2. 


Fig.2 : Geodesic trajectories of control masses in the vicinity of a negative mass
- Objects with positive mass M < 0 indifferently repel other masses, whether positive or negative.
Let's consider now  a couple of opposite masses: 



Fig.3 : Runaway effect.

First paradox: the positive mass flees, pursued by the negative mass, in violation of the principle of action-reaction. 
Second paradox: the couple accelerates indefinitely, but this increase in speed takes place at constant energy since the kinetic energy of the negative mass is itself negative. 

3 – Two attempts to introduce negative masses in Einstein's model
These attempts remained within the geometric framework of General Relativity, described by Einstein's field equation. 
In the first one (Benoit-Lévy a G. Chardin [10]), the authors take Dirac-Milne's model, where the positive and negative mass contents give a globally null density. The expansion then takes place in a linear way, in contradiction with the evidence of cosmic acceleration ([3], [4], [5]). The authors propose that the negative mass may correspond to antimatter. They imagine, without providing any scientific support, that this cosmological antimatter could be repelled by ordinary matter by suggesting that this phenomenon could manifest itself during the experiments being set up at CERN, Gbar and Alpha, intended to highlight the behavior of antimatter created in the laboratory, in the Earth's gravity field. 
In the second one in 2018 [11], the Englishman Jamie Farnes plans to unify dark matter and dark energy into a single entity, identified with negative mass.
To do so he is forced to invoke an undescribed phenomenon of constant creation of negative mass, keeping its density constant throughout the cosmic expansion, so as to guarantee the constancy of the negative cosmological constant, according to the relation. 
(3)                                                          
Since his model is always presented as a solution to Einstein's equation, the runaway phenomenon is automatically part of it, which he then considers as the mechanism producing the high-energy particles constituting cosmic rays. And he concludes: "From this perspective the runaway motion is not a challenge for negative mass models, but a rather useful observational constrainst". 
What is however interesting is a simulation result where a Hernquist galaxy, composed of 5,000 positive mass points, is surrounded by 45,000 negative masses
 These negative masses, exerting their repulsive action on the components of this galaxy, makes possible high rotational speeds at the periphery. On figure 4 the red curve gives the profile of the rotation curve for this galaxy, whereas the black curve represents this profile in the absence of the negative mass environment: 


4 – Empirical approach, simulation results
In the mid-nineties [12], numerical simulations were used to explore the behavior of a mixture of positive and negative masses, satisfying the principle of action-reaction, i.e. according to hypothetical laws: 
(4)
- Masses of the same sign attract each other according to Newton's law.
- The masses of opposite signs repel each other according to "anti-Newton". 

The first result did not bring any element likely to orient research in astrophysics. A percolation of the two species was then observed. See figure 5: 
 
Fig.5 : Result of a simulation  with 
An idea then emerged, consisting in considering the behavior of a mixture of positive and negative masses, governed by these hypothetical laws of interaction, in the case where the negative mass is dominant. The following result was then obtained: 

Fig.6 : Result of simulation 1995 [12]  with  
Although they are only 2D simulations, very primitive, carried out with two times 5,000 mass points, the creation of a lacunar structure of the positive mass appeared. In the center of each cell: a negative mass conglomerate, repulsive. The negative masses, denser, formed the first, by gravitational instability, a regular distribution of negative mass conglomerates, repelling the positive mass into the interstitial space. The idea emerged that the large-scale structure of the universe could result from such a mechanism, implying a deep asymmetry between the two populations. Below are the Jeans times of the two populations. The Jeans time of the negative, self-attractive population, being weaker, structured itself first, leading the game. 
(4)                                            
Assuming that these negative masses, of negative mc2 energy, emit photons of negative energy that do not produce any optical observation, it seemed possible that the very large scale structure (VLS) is organized around basically invisible conglomerates of negative mass. See further the question of the Great Repeller. 

5 – First attempt at bimetric modeling. 
Nevertheless the results of the numerical simulations were encouraging. To try to integrate the interaction laws (4) in a relativistic framework was the obvious fact rest. With a single field equation and a single metric the runaway effect was inevitable. To avoid it, the field had to generate not one family of geodesics, but two, the first translating the behaviour of negative masses and the second that of positive masses. Two metrics were therefore needed, i.e. two Ricci tensors  appearing in the first members of two field equations. 
In 1994 [13], a first approach consisted in proposing the set 
 (5)                                                   
(6)                                               
The minus sign, introduced in the second equation, made it possible to find, by implementing the Newtonian approximation, the laws of interaction (4). The construction of joint metric solutions also allowed [12] to introduce a negative gravitational lens effect, the two metrics associated with a mass M, positive or negative, becoming:
(7)                        
(8)                        
but the system (5) + (6) refused to produce the asymmetry that had proved so fruitful in the simulations. The solution was found in 2014 [14] by giving the system of equations the form: 
(9)                                                   
(10)                                               
When a FLRW metric is introduced into Einstein's equation, two differential equations are obtained which contain the first and second derivatives of the scale factor a. Compatibility between these two equations (existence of solution) results in energy conservation:
(11)                                                                       
With two equations we have four equations that must be compatible. In the case of equations (5) + (6) it is these compatibility conditions that lead to an uninteresting trivial solution (Dirac Milne's model).  But the system: 
(12)                                  
(13)                              
in which two FLRW metrics are introduced then leads to the following condition of compatibility between the two pairs of equations 
(14)                                              
Which is nothing but energy conservation. It was desirable to produce a Lagrangian derivation of these equations from an action. We produced one in 2015 [15], which turned out to be quite close to that of S. Hossenfelder [16] but hers seemed to be more solid and this is why we chose to link our own work to her.
The editorial board said that in the previous writing of the article it was said, we quote: 
For example, the text around the discussion of  Hossenfelder’s work is so confused that I cannot tell if the authors are criticizing that work or building off it (or both).
In what follows we will show that her work could not lead to a true cosmological model and to a set of computational results that could be successfully confronted with the observations, because she did not see that these required exploring the hypothesis of a very asymmetrical world, where densities, speeds of light, scale factors are radically different. This is the reason why she could not develop her essay. 
Obviously, it will remain to justify why the universe, at the end of the Big Bang, could have presented this configuration. This will be the object of a future paper of which it will not be reported here.

6 - Massive bigravity. 

We will begin by discussing the first attempt to build a model with several metrics. 

s T.Damour and I.Kogan [17] introduce the formalim of fully non-linear bigravity. 
They consider two branes, « right » and « left », interacting through massive gravitons. They introduce Lagrangian densities in the action : the Ricci terms  , , the terms corresponding to positive matter and negative matter , are based on the corresponding four-dimensional hypervolumes  and   . They introduce an interaction term : based on an « average volume factor » . The variational method produces a system of two coupled field equations. In the second members are the tensors representing the sources of the two materials "right" and "left" as well as the terms and reflecting the interaction between the two. The authors then consider different models: branes, KK, non-commutative geometry. This first article is quickly followed by a second [20]. The scientific community apparently considered at the time that this essay represented an important contribution since the journal Physical Review D devoted 17 and 25 pages to these two articles, despite the fact that no data emerged that can be compared with any observational data.  


7 – Bimetric theory with exchange symmetry. 

In 2008 [16] S. Hossenfelder published in the journal PRD a theoretical essay entitled " Bimetric theory with exchange symmetry". As she says in her section I, we quote: 

« We consider a bi-metric theory with metrics g and  of Lorentzian signature that define two different ways of measuring angles, distances and volumes on a manifold M  » . 

These are the same metrics that, in our own work, are called . For the sake of homogeneity we will keep the notations of her paper. 

Still in this section I, she writes :
 
« We will further introduce two sorts of matter on M : one that moves according to the usual metric g and the measures it implies, the other that moves according to the other metric . We will refer to these fields as g-fields and h-fields, respectively. » 

Using her "pull over" technique, she defines an action that corresponds to equation (32) in her section IV:  




-  are Ricci's scalars associated with its metrics g and . 
 - being the determinants of both metrics,  are the corresponding 4-volumes. 

-  is the g-field and  the h-fields

She then performs a "bi-variation". It is then necessary to introduce a coupling relation, which she does with equation (27) in section III



 This is the covariant version of the coupling relationship that we used in our article [15], in a work subsequent to hers. Hence the obvious kinship between the two systems of coupled field equations. Hers corresponds to equations (34) and (35) in section IV of her article, and is written as follows: 

  


In section V and in her appendix B, she specifies the interaction laws that follow from the model. They correspond with our hypothesis (4). She notes, as we do, that this solves the runaway paradox. We find in section V of her paper the pair of Schwarzschild's solutions (7) and (8) and the negative lensing that results from them. 

In this system are positive constants, see at the end of his section IV. The properties of element a are specified in section I : 

« In this formulation  the introduced map a is a convenience and not a dynamic field ». 

She calls a and b the scale factors present in the FLRW metrics (38) and (39) of the section VI of her paper:




She chooses to take the same value c = 1 of the speed of light for the populations g and .  She also gives Einstein's constant the unit value and assumes from the outset that the two curvature indices are the same. 

As we find the cube ratios of the scale factors of our equations (12) and (13). When searching for a FLRW solution we used the mixed versions of the system of equations. Ours became :

(15)                                  
(16)                              

Her system is : 



(17)


(18)


The introduction of FLRW metrics in her system of coupled field equations leads to two pairs of equations. She gives only one pair. These are equations (42) and (43) where we have restored her typing error by inverting the terms 



The other two equations and the associated compatibility equations are not present. It should be remembered, as can be seen in the content of her conclusions in section VII, that the author's aim was not to create a new cosmological model but to try to model the source of the cosmological constant Λ through fluctuations related to this bimetric situation. In section III of the paper the author examines different configurations. In the approach followed, the density is positive, which has been imposed in such a way that evolution equations (42) and (43) lead to similar evolutions. It is only by making a peculiar choice of signs in the action that the author manages, with positive masses to make them repel each other, we quote, at the end of her section III : 
 
Thus, because of the presence of negative gravitational masses …

A little further on, in section VII we find the sentence

- « We will assume that the field content for both, the g-fields and the h-fields, is identical such that we have e.g. two copies of the Standard Model ».  

being positive constants, which she erroneously considers as free parameters, the choice effectively leads to a trivial model where cosmic evolution is unchanged and results in a Friedmann model, according to the choice of k, with strictly parallel evolutions of the two populations


8 – Confusing conclusions and a lack of elements that could be compared with the observations in the 2008 article of S.Hossenfelder.
Using the phrase from the editorial board :
 For example, the text around the discussion of  Hossenfelder’s work is so confused that I cannot tell if the authors are criticizing that work or building off it (or both).
Our answer is that the Lagrangian derivation operated by Sabine Hossenfelder is mathematically exact, so that this construction of coupled field equations can be retained as a method of constructing a bimetric system. On the other hand, her article ends in confusion. We will quote excerpts from part VII of his article.

- « In the previous section we have studied the extension of GR in whose framework sources with negative energy appears in the equations ».These additional h-fields interact only with our standard matter, and thus couple only extremely weakly. » 

The proposal is perfectly clear. It envisages the introduction of a negative energy content, thus corresponding to elements , therefore of negative mass. It would therefore have been logical to introduce an equally negative mass density . At this stage one is looking at how these massesinteract. While this is a major element of the approach this is not immediately and clear (which can be done immediately thanks to the Newtonian limt). These answers have to be found in the text. In section V we read :

- « Since h is just a Schwarzscild metric with negative (…) source one see e.g. by taking the Newtonian limit thet a h-particle will be repelled by the g-source. » 

In section VIII we find: 

- « We further investigated the spherical symmetric example with the source of usual matter, and we found that the newly introduced particles would be repelled by this source ». 

Translation : a masse m repels a mass  . 

As confirmation, the author writes in section V: 

- « Since both kinds of matter repel, one would expect the amount of the h-matter in our vicinity to presently be very small ». 

So there is mutual repulsion of these masses , even though the mass densities  are both positive (...). 

But while S.Hossenfelder is an excellent mathematician, she seems less comfortable with physics questions. She thinks she can simplify calculations by taking all constants equal to unity, and does the same for Einstein's constant . However, the Einstein constant is fundamentally negative. In this logic she should have given it the value - 1.  It is this choice that dictates her choice of signs in her field equations, a source of confusion. 

The fact of invoking the weakness of gravitational interaction would only make sense if this force was compared to another force, essentially the electromagnetic interaction force 1039 times greater. The latter is absent in cosmological models where the cosmic scenario, involving isotropy and homogeneity, includes the fundamental assumption of the electrical neutrality of the universe, otherwise the smallest charge would lead to a very violent expansion. In this sentence S. Hossenfelder means that the existence of this entity of negative mass would couple weakly with positive mass, whereas the interactions  are of the same order of magnitude as the interactions .  

Further on: 

 - « The model we laid out is purely classical. Nevertheless it is worthwhile to consider the vacuum expectation value of the stress-energy tensor for quantum fields that are coupled to the classical background. »

She therefore considers her trial as a simple modification of the standard model. Thus the phenomenon represented by this "weak" coupling of the h-field with the g-field, would be at the origin of this negative energy of the vacuum, translated by the presence of the cosmological constant in Einstein's equation. Consequently she writes  : 

- « We will assume that the field content for both, the g-field and the h-field, is identical such that we wave e.g. two copies of the Standard Model ». 

It is then easier to understand why she chooses to pose  , which gives it identical evolutionary equations (42) and (43), when she considers a mixture of two similar entities. The world of negative masses represents for her a kind of ghostly entity which by its contribution to the gravitational field would not bring in itself a perturbance sensitive to cosmic dynamics ("two copies of the Standard Model") but would reveal its presence through fluctuations which would then be the source of the effect attributed to vacuum energy, to the cosmological constant. The author then focuses her interest on the regions of the universe that are free of matter, on its "empty" regions, and she writes :

- « If we consider the vacuum solution in the model with exchange symmetry however, we expect a symmetry between both metrics. In the case with maximal number of space-time symmetries, both would just be the Minkowski metric. We then have  and the pull over are just identity. Since the matter content of both types of fields is identical (…), this means that the source terms in equations (34)  and (35) cancel identically, ,no matter how large their values are. » 

The reasoning here becomes contradictory. The model no longer corresponds to "two copies of the standard model". Field equations with null second members lead to the Dirac-Milne model with linear expansion as a function of time. These hypothetical middle fluctuations are not described. One simply reads: 

- « Wether or not this solution is stable or would run away is the constants did not exactly cancel requires further investigation. » 

It is therefore not known how an instability of this vacuum, presented as a mixture of two types of matter with identical densities, could generate a field corresponding to a negative energy density, two orders of magnitude greater than the gravitational field associated with ordinary matter, causing the acceleration of the expansion translated by the observations of high-redshift supernovae.  

She writes: 

« Since we now have only gravitationnally interacting density contribution that is negative, and one further would hope for symmetry reason that both densities are of the same order of magnitude (…) the total gravitating density can be smaller than the observed one. Then the relative density fluctuations can be smaller than the observed one ».

Indeed, how can one hope to create a field one hundred times more intense than the field due to ordinary matter from fluctuations appearing in an environment where, locally, the density of the second matter is of the same order of magnitude? 

And she concludes:

- « Then the relative density fluctuations could be larger ».

Very intense fluctuations, produced by what mechanism?

And we read: 

- « Besides this, both components of matter repel each other which is an effect usually not present ». 

Of course, since in the model ΛCDM with which she tries to stick, the confinement of galaxies, the flatness of their rotation curves is interpreted by the presence of a halo of dark matter. 

To conclude, Sabine Hossenfelder sees in the negative gravitational lens effect associated with the Schwarzschild Solutions joined together, evoked in section III, the only possibility of putting hypothetical fluctuations signalling, in vacuum, regions constituting localized sources of negative energy. She writes: 

- « Another feature of the scenario becomes clear from the previously discussed example of the Schwarzschild metric. If there was a localized source of negative energy, it would act as a gravitational lens-but unlike usual matter this would be a diverging lens since it would repel our (usual) photons. Such a lensing event would typically lower the luminosity of the source, an effect that could potentially add up over distance if the contribution of such sources is substantial. The detection of diffractive lensing event could serve as a smoking gun for the here proposed scenario ? ».

S. Hossenfelder rediscovers here the effect that we had already described in 1995 [12]. 

In conclusion, as a good mathematician, well versed in the techniques of differential geometry and the calculation of variations, she gave in 2008 a coherent and solid mathematical foundation to a model we introduced in 1994 in its infancy, essentially supported by numerical simulations.

But, like Pyrrhus, she has not been able to exploit the physical implications of her work, allowing a confrontation with observations.


9 – Adaptation of the system of coupled field equations. 

We are going to adapt her own model, by modifying the signs, that is to say by considering that the density   and the pressure  are this time negative. We assume a priori that the speeds of light  as well as the curvature indices  may be different. We will make the cosmological constant reappear (half present in the expression of the action through the factor , which then disappears).  There is no reason why Einstein's constants  in the equations should be a priori identical. Under these conditions we will write the FLRW metrics (in a more classical form). Following the same mathematical path but modifying the signs, the system of the two coupled field equations is written as follows:

(19)                                

(20)                              

As far as Schwarzschild's external solutions are concerned, nothing has changed. But the "second masses" are negative, as well as density and pressure . To consider the evolution of this system of two interacting materials, we will write the FLRW metrics, allowing the system to have two speeds of light. One speed c for (ordinary photons) of positive energy and one speed  for photons of negative energy, travelling according to the geodetic null of the metric h.

(19)                                           

(20)                                           

So we have a single manifold M equipped with two metrics g and h . The cosmic history resulting from the introduction of these metrics in the field equations will be translated by the functions giving the evolution of the scale factors . We write the system of field equations in mixed form:

(21)


(22)


The source tensors of the field are given the form: 

(23)             

By introducing these metrics into the equations we obtain two pairs of differential equations, the first pair containing the first and second derivatives of the corresponding scale factor a and the second pair containing the first and second derivatives of the second scale factor b. 

(24)                                        

We get the equations: 

(25)                                     

(26)                      

(27)                                     

(28)                                

One cannot, as Hossenfelder does, consider only equations (25) and (27) and deduce from them evolutionary equations by treating the parameters  as independent quantities. They are not. The imperative of the existence of a solution must be assured. Their values are determined by the compatibility relations that link equations (25), (26), (27), (28). The detailed calculation is given in Annex I. It is modelled on the classical calculation of the FLRW solution of Einstein's equation, which results in an energy conservation relationship of

 (29)                                                                  
which gives  for the universe of dust and  for the universe of radiation. Here we get something similar (the detail of the calculation is given in Appendix I).

 Equations (25) and (26) then give :

(30)                                      

And equations (27) and (28): 

(31)                                     

There are two possible scenarios. If we are in a universe of dust: 

(32)                         
 
Which gives a generalized law of energy conservation with

(33)                                                                


(34)                                                 


In the case of a universe made up of radiations the compatibility leads, with: 

(35)                                                          

to the generalized conservation of energy, in this form: 

(36)                                            

If one opts for this modeling it would then be necessary to rewrite the system of field equations: 

(37)                         
(39)                       

corresponding to the matter dominated era and to the radiation dominated era. 

We can show, just as we have that: 
(40)                                                                   
that we get : 
(41)                                                                

By taking a cosmological constant null in the the equations, for the universe of dust it comes: 

(42)                                                            

(43)                                                         

(44)                                                              

(45)                                                           

As the measurements referring to our matter dominated era show an acceleration, we deduce that the global energy E is negative. Negative mass dominates.  This confirms the hypothesis that had prevailed to lead to interesting numerical simulations. Equation (42) imposes that the index of curvature k is -1. As a consequence, all the negative masses are in a state of deceleration. These equations are therefore written: 

(46)                                                            

(47)                                                            


 
10 – An universe dominated by negative mass.

We can then write equation (46) according as: 

(48)                                                        

The exact solution of such an equation has been given by William Bonnor [9]. Only the part of the solution corresponding to the matter dominated era can be considered.  By pushing this solution to the origin of time, the zero value of the chronological variable, the mathematical solution gives a non-zero scale factor a value. The model accounts for the acceleration of the expansion. ([3],[4],[5]). The mainstream CDM model predicts an exponential expansion related to the fact that the energy-matter equivalent of the cosmological constant remains unchanged when the universe expands. Conversely, the density of negative mass decreases and equation (46) assigns an asymptote to this expansion. 

The comparison of the predictions of this model with the data of 700 type Ia supernovae proved to be excellent [19] .



Fig.7 : Comparison to observational data from 700 1a-supernovae [19]
 
The interest of this approach is that it unifies the two invisible components of the universe into a single entity, a negative mass, which now fulfills the functions performed by dark matter and dark energy.


11 – Radiative era.
The compatibility condition of the four equations gives  . Assuming that the system is always dominated by the negative energy content we would always have a positive acceleration: 

(49)                                                                

But as it stands, this model does not provide the reason why such a dissymmetry exists between the two entities. In a next article we will show how this asymmetry manifests itself, starting from a totally symmetrical situation, through another description of the radiative eras of the two populations. This approach will explain in passing the remarkable homogeneity of the early universe and will provide an alternative interpretation of the fluctuations of the CMB.
Let us now examine what can emerge from the model, as it stands, in the matter dominated era phase.

12 – With respect to local relativistic observational data. 
The agreement is immediate. As noted by S. Hossenfelder in section IV of his article: 
« Since both kinds of matter repel, one would expect the amount of h-matter in our vicinity to presently be  very small ». 
So the system becomes: 
(50)                                   
(51)                                 
The first equation is simply that of the classical GR. So all local verifications like the explanation of the advance of Mercury's perihelion and the deviation of light rays by the Sun also derive from the model.

12 – Galaxy modeling. 
It has been possible to build a model of a galaxy with spherical symmetry surrounded by negative mass, the latter having a confining effect on it. Self-gravitating stellar systems had already been modeled in 1942 by S.Chandrasekhar [20] using a solution of the Maxwell-Botzmann type of the Vlasov equation, coupled with the Poisson equation. The stars in galaxies form non-collision sets.The Bolzmann equation is written as follows: 
(52)                                                       
 being the gravitational potential and  the mass density, Poisson's equation is 
 (53)                                                               
    being the mean velocity, residual velocity (term used by astrophysicists, while fluid mechanics will speak of thermal agitation velocity) is . We define an operator  
 (54)                                                             
We can then consider two Vlasov equations, written in terms of residual velocities, coupled by the Poisson equation. These equations are written: 

(55)                              
(56)                              
The terms  are the dyadic matrices [23] formed from the different vectors and gradients. The term  represents the scalar product of two dyads defined ([21] page 16 eq. 1.31.4) by . The logarithm of Maxwell Boltzmann's distribution function f is a spherical polynomial as a function of the components (U,V,W) of the residual velocity. Elliptic solutions have been developed, where the Maxwell Botzmann function is only a special case, where  is then a polynomial of degree 2 as a function of these components. We know that the distribution of stellar residual velocities around the sun is not isotropic but corresponds to an ellipsoid of velocities where one of the axes is roughly double the other two. A model of a spheroidal galaxy (or globular cluster) corresponding to the drawing below has been constructed:



Fig.8 : Ellipsoid of velocities in spherical symmetry. 


In spherical symmetry the two transverse axes of the ellipsoid of the velocities, which are equal, differ from the axis pointing towards the center of the galaxy. For an axisymmetric system the two transverse axes differ, which has been developed in reference [24]. In the configuration of figure 2 the shape of the velocity distribution function corresponds to: 

(57)                                           

For the negative mass environment a Maxwellian velocity distribution is used: 

(58)                                             

By introducing these functions into the two Vlasov equations (55) and (56), in stationary regime, and coupling with the Poisson equation. The calculation is facilitated by the use of dyadic algebra [21]. We obtain exact solutions that model the confinement of this spheroidal galaxy corresponding to figure 3. 



Fig.9 :Spheroidal galaxy, or globular cluster, or cluster of galaxies.

This model highlights the role of the negative mass environment that confines both spheroidal galaxies, clusters of galaxies and, in the case of galaxies, allows to reconstruct the flatness of their rotation curves. See a more recent result on figure 4 [11]. These objects of positive mass are thus housed in gaps in the negative mass distribution. This gap being equivalent to an equivalent positive mass, this one will be the main responsible for the observed gravitational lens effects. The model therefore accounts for this set of observations. From this point of view it is an alternative to the dark matter model, but does not invalidate the existence of the latter.

Note: It is unfortunate that we do not have the possibility to develop a galaxy formation scenario using simulations. The process of constitution of the large-scale structure highlights a new phenomenon: the intense compression of the positive mass, due to the repulsive effect of two adjacent negative-mass conglomerates, resulting in the heating of this matter in plates, offering an optimal geometry for a rapid radiative cooling, favoring the formation of primitive galaxies. 

A solid body rotation is then introduced. The following image comes from numerical simulations carried out at the DAISY laboratory in Hamburg in 1992 by the student Frédéric Descamp. In a few turns, after a transient regime, a barred spiral is formed, lasting for thirty turns [23].



Fig.10 : Barred spiral from numerical simulation (1992 : 2x10,000 points)

The evolution of the kinetic moment of the galaxy, along with the establishment of its rotation curve differing from the initial solid body rotation, is as follows: 


Fig.11 : Evolution of the kinetic moment (1992 : 2x10,000 points)


We are in the presence of a phenomenon of dynamical friction. In collision dominated systems, the transfer of kinetic moment and energy takes place by collisions. In non-collisional systems these exchanges, which reflect the dissipative mode in these environments, are carried out via the appearance of inhomogeneities, density waves also called tidal effects. The interaction implies that the shape of the density waves in the positive world finds its counterpart in the negative world. The curve above shows that the interaction is intense when the negative mass environment is present and when the galaxy rotates as a solid body, which is also revealed in the images of the transient phase. The variation decreases when the galaxy has reached its differential rotation regime with flatness of the curve at the periphery. These simulations could only be carried out in Germany for a few months, as the student was quickly called to order by his hierarchy. As we had no access to adequate computing resources in France, we had to abandon this research direction with regret. In addition, in spite of the strong mathematical support, the specialized journals rejected these works without reading them and replied "sorry, we don't publish speculative works".. 

13- Large-scale structure, the problem of the Great Repeller.
In 2017 [7] a very large scale map of the universe is published, covering a cube of one and a half billion light years on each side. This mapping is accompanied by a presentation of the velocity field which highlights the existence of a vast spheroidal region exerting a repulsive effect on the surrounding galaxies and which has been named Great Repeller. 


Fig.12 : The Great Repeller

The model interprets this observation as the presence of one of the negative mass conglomerates determining the structure of the universe on a very large scale, formed by the gravitational instability of the negative, self-attracting mass . The dark matter hypothesis does not provide an answer in the sense that no scenario is proposed that would justify the existence of a large void.  

This scheme of a distribution of conglomerates of negative mass would then have the consequence of weakening the luminosity of distant sources by negative gravitational lens effect. This is exactly what is observed for redshift galaxies greater than 7. 

As it stands, the negative mass model presents itself as a credible alternative and the results obtained deserve to be brought to the attention of the scientific community so that my subject can be discussed. But we will move on to other areas of research where dark matter does not provide answers.

Insofar as the present model, with respect to these aspects, presents itself as an alternative to the mainstream model ΛCDM the relative importance of the negative mass is the same as that of the set dark matter plus dark energy: 



Fig.13 : The components



14 – Primordial antimatter, nature of the negative mass. 

In the accepted scientific scheme, matter and antimatter are formed from primitive radiation, as long as the energy of photons exceeds the energy equivalent of these matter-antimatter pairs. When the expansion lowers this temperature these syntheses cease and these elements disappear by annihilation. Fossil radiation is considered as the remnant of these annihilations. There is currently no theoretical model that explains why one particle of matter in a billion remained, nor why we have never had to highlight its counterpart in the form of primordial antimatter. 

The Russian Andrei Sakharov [24] started from a synthesis image of baryons from quarks and antiquarks from anti-baryons. According to him the rate of synthesis of baryons would have been faster than that of anti-baryons. The expansion would have frozen this situation and there would exist in our universe a remnant of free antiquarks, in the ratio three to one. He further suggested that a twin universe would coexist with our universe, which would have known an opposite situation and where anti-baryons and quarks would subsist in the free state. He also suggested that the time arrow of this other universe would be opposite to ours and that it would be enantiomorphic. But he had not envisaged the involvement of these two regions. Below is a didactic image illustrating Sakharov's model. 




 Fig.14 : Didactic image of Andrei Sakharov model


We can consider the cosmological model with negative masses as suggesting the following scheme: 



Fig .15 : Link to the Sakharov model

One can imagine a reversal of time at the time of the Big Bang, a situation that brings a form of answer to the question "what was there before the Big Bang".

It so happens that in 1970 the French mathematician J.M.Souriau brought an original answer to T-symmetry. His approach is the following. Starting from Minkowski's isometry group, the complete Poincaré group, he determines, by the technique of the group's coadjoint action on the dual of his Lie algebra [25], the characteristics of the motions of the different particles that inscribe their motions in it. These objects are of two kinds:

- Photons, characterized by their E energy and spin s.  

- Particles with an energy E (with a rest mass m, according to E = mc2) and an impulse p. 

Poincaré's group, represented by the matrix (5.5), C being the space-time translation vector : 

(59)                                          

This group is constructed from the Lorentz group, represented by the matrix (4,4), axiomatically defined according to: 

(60)                              

Thus defined, this group has four connex components: 

-  is the neutral component because it contains the neutral element of the group. It does not reverse time or space.

-  inverts space but not time: P- symmetry. 

-  Inverts time but not space: T-symmetry

-  Inverts both time and space: PT symmetry. 

The first two components form the orthochronous subgroup  or restricted Poincaré group.  The other two components form the antichronous subset  . We can build the complete group from the orthochronous group thanks to the properties which is translated by writing the matrix

(61)                                                   

The action of the group on its moment [25] causes, starting from a movement of moment M, all possible movements of moment M' likely to be inscribed in Minkowski's space to unfold. It is translated by the relations ([25] eq. (13.107) on page 172): 

(62)                

P is the energy-impulsion 4-vector and  p the impulsion 3-vector.  : 

(63)                                                              

From the examination of these relations (62) and (63) we find the result of Souriau ([25] page 190, equation (14.7) ): 

T-symmetry reverses the energy and pulse, but not the spin.

So that the analysis of the properties of space-time shows that T-symmetric motions should be included, that would simply be those of particles of opposite energy, for photons, and of negative mass for matter. Until 2011 nothing emerged from our physics that could give credit to this idea. But the discovery of the acceleration of expansion, attributed to the action of negative energy, gave credence to the idea that there could exist particles with negative energy, which could be particles with negative mass and photons with negative energy. This possibility of inversion of the time coordinate can be read in any case in the expression of the metric, invariant by T-symmetry, P-symmetry and PT-symmetry: 

(64)                                                  

But this inversion of the time coordinate t does not automatically mean the inversion of the proper time s ! 

The cosmological model hosts negative masses and negative energy photons that and our instruments cannot capture. It is a simple extension of Minkowski's geometry . As this inversion goes hand in hand with the inversion of time we call it: 

Janus Model

The two folds are linked by a PT-symmetry relationship, like Sakharov's twin universes. 

The matter-antimatter duality finds its geometrical translation by inscribing the movements in a Kaluza 5D space. The corresponding group is then translated by the matrices (5.5): 

(65)                                             

The value represents a C-symmetry. This doubles the number of related components in the group. The group acts on the five-dimensional Kaluza space-time 



The translation subgroup is introduced along this fifth dimension. According to Noether's theorem this is translated by the constant of a scalar q , which is then the electric charge. 

Matter/antimatter symmetry is geometrically translated by the inversion of the fifth dimension . Let us start from Feynmann's idea according to which by applying to a particle a double inversion of space and time, it behaves like an antimatter particle. This is concretized by passing to the Janus group :


(66)                                              

Through the matrix the value  operates an inversion of space and time, at the same time as an inversion of the electrical charge. In passing, the inversion of time leads to the inversion of energy and mass. This Λ-symmetry is that which corresponds to the Janus cosmological model. By adding the value we install the duality of antimatter in the world of negative masses. 
Let us note in passing that one can add as many additional dimensions to Minkowski's space as quantum charges  

(67)                            

The complete calculation of the action of this group on its momentum is given in Annex II and leads to:

(68)                  

So there are two antimatters: 

- The C-symmetric of ordinary antimatter, with positive mass and positive energy. Let us call it "antimatter in the sense of Dirac".

- The PT-antimatter,  PT-symmetric of our own matter, with negative mass and negative energy, which we will call antimatter in the sense of Feynmann. 

If Sakharov's idea is then implemented, the world of negative masses would be populated with antimatter of negative mass and energy. Essentially: 

- Negative mass antiprotons

- Negative mass anti-neutrons

- Negative mass anti-electrons

- Photons of negative energy

- A residue of negative energy quarks. 

It is of course impossible to highlight these components individually, especially since this negative mass is almost absent in the solar system.
The model is falsifiable on many levels. With the foreseeable progress of observation techniques, it will be possible to try to detect at the center of the Great Repeller formation the presence of a conglomerate of negative mass, which would then reveal its presence by a significant attenuation of the magnitude of the distant sources. If this attenuation reveals the presence of an object of limited size, it will invalidate any interpretation in terms of a gap in the dark matter. 
The cooling time of a protostar increases with its mass. These conglomerates, which form rapidly after decoupling, can be compared to protostars of gigantic mass whose cooling time exceeds the age of the universe. They are thus spheroidal sets made up of anti-hydrogen and anti-helium emitting negative energy photons, which our instruments cannot capture, in the red and infrared range. In this world of negative masses, there is no atom heavier than these. There are no stars, no galaxies, no planets. 
Life is absent from it.

The Janus Model provides an answer to the question of the lack of observation of primordial antimatter. 

It predicts in passing that antimatter created in the laboratory, with a positive mass, will behave like ordinary matter in experiments to demonstrate its behavior in the Earth's gravitational field (Gbar and Alpha experiments).

It is the only one to attribute a precise identity to the invisible components of the universe and to specify the nature of the objects which do not constitute it. 

 
If one replaces the singularity Big Bang by a bridge connecting the two folds of universe in interaction, which are in a way the Right side and the upside down side of the hypersurface space-time, the model brings an original answer to the question "what was there before the Big Bang? »



Fig .16 : Elimination of the initial singularity

The inversion of the time coordinate is not a problem in this extension of general relativity since metrics, field equations, for all equations of physics are time-reversible. What does Quantum Mechanics have to say about this? If we refer to a reference work, that of S. Weinberg [26] in section 2.6 (pages 74 to 76). We will find two arbitrary choices concerning the operators P and T for the inversion of space and time. In order to avoid the emergence of negative energy states, which are considered a priori impossible, the following two arbitrary choices can be made, 

P linear and and unitary  ( LU )

T antilinear and anti-unitary (AA)


15 – Opening of a new research field in Quantum Mechanics [6]. 

It is well known that the equations of relativistic quantum mechanics (Klein-Gordon, Dirac) naturally highlight negative energy states. They have always been eliminated by considering that they lead to negative probability densities. The solution that physicists have found is then to replace, in a rather artificial way it must be admitted, the so-called probability densities by charge densities: this is the birth of antiparticles (in the commonly accepted sense).

However, if we look a little closer at these probability densities, we see that they can be reinterpreted as real probabilities, positive, if we consider that negative energy states are also associated with negative masses. This is particularly striking with the Klein-Gordon density, which involves the ratio
(69)                                                                    
Probabilistic interpretation is therefore compatible with negative energy states provided that energies and mass are simultaneously negative. And how could it have been otherwise with Einstein's relation at rest E =m c2 ? Thus quantum mechanics is the ideal ground for reintegrating negative energies. However, the consequences must be discerned. One of them is that the temporal reversal operator will henceforth be considered as a linear and unitary operator [8]. 
We know, in fact, that a symmetry operator must necessarily be [26].  
- Linear and unitary (LU)
or
	- Anti-linear and anti-unitary (AA)
It is customary to choose, for a spatial inversion P, the choice LU and for a temporal inversion T the choice AA. Thus, the action of these discrete symmetries on the fundamental operators of quantum mechanics as well as on the imaginary it can be summarized by:
(70a)                                       
(70b)                                    
The fundamental relationship of quantum mechanics: 
(71)                                                                     
is then invariant under (70a) as well as under (70b). 
Moreover, the symmetry thus chosen ensures the invariance of the energies
 (72)                                                                   
Positive energies, if we limit ourselves to them, therefore remain exclusively positive. On the contrary, in [8] we have opted for the choice LU, for the two inversions, which leads to the following result: 
(73a)                                     
 (73b)                                   
both ensuring the invariance of (69). The major difference is that the symmetry PT leads this time to a change of sign at the level of the energies:
(75)                                                         
There is nothing to prevent, physically, mathematically and from a probabilistic point of view, to consider these negative energy states as long as they are assigned a negative mass.  Moreover, it even seems that this additional possibility is more rigorous if we stick to mathematics, since implying that T is linear, it is in agreement with its usual realization (cf. [26] Eq (2.3.16), p. 58, for example):
(73)                                                          


17) Challenging the inflation model. 
If we want to arrive at a coherent cosmological model, we have to negotiate all the elements coming from the observations. One of them is the extreme homogeneity of the CMB, image of the early universe. The only explanation put forward so far is the hypothesis of a considerable inflation, attributed to a field of inflatons. As no alternative theory was presented, this model ended up being considered as part of a "standard model", whereas no credible model of inflaton was born. 
Various attempts have been made (&&&ref) using a variable speed of light. But these attempts have been hampered by the loss of Lorentz invariance. Moreover, the observational data were opposed to the variation of c, if only through its influence on the fine structure constant. 
Although the scientific community did not pay attention to this model, as early as 1988, that is to say 33 years ago, we published an article [27]  where we introduced the idea of joint variation of all the constants of physics, in agreement with the correlative variation of space and time gauges. 

In a second paper [28] an attempt was made to deal with the redshift phenomenon by trying to introduce a different variation of the electromagnetic parameters. But later, years later, in [12] we abandoned this idea and preferred to situate this phase "with variable constants", as part of the radiative era.   

These constants, as well as these two gauges, are present in the equations of physics, remembering : 

- The field equation
- Maxwell’s equations
- Quantum mechanics’ equations. 
The quantities to consider are: 
The six constants of physics: 
- G : constant of gravitation
- c : speed of light
- h : Planck constant
- e : elementary electric charge
-  : magnetic permeability of vacuum 
- m : all kinds of masses
We suppose all masses experience the same gauge variation. 
To this must be added 
- a :  space scale factor. 
- t : time scale factor.  
We must therefore consider varying these eight quantities together: 
(74)                                              
We then show  [12]  that there is only one generalized gauge relation, involving these eight quantities, leaving all the physics equations invariant. The details of the establishment of these different relations can be found in the appendix III.
In these conditions, if we choose one of these quantities as a variable, the other seven are deduced. As the equations of physics remain invariant, the same is true for the fine structure constant. Lorentz invariance is also assured. It is convenient to take the scale factor a, related to the expansion process, as a guiding variable. The variations are then: 
(75)                      
Since the variables , dielectric constant of vacuum, and  are related, we deduce that is absolute constant. We verify that the invariance of the Lorentz metric 
 (76)                                                
according to the above relationships. 
As recalled in the appendix III these gauge relations imply that : 

- All characteristic lengths vary as a

- All characteristic times vary as t

- All energies are conserved. 

The third property is then in contradiction with redshift measurements, which boil down to evaluate the energy loss of photons, due to the expansion. Thus this form of "gauge" evolution can only be located during the radiative era. 

What is the observable, related to this mode of evolution (of gauge), if there is no redshift ? Answer : it is the evolution of the cosmological horizon. 

(55)                                         

There is therefore no longer any need for inflation. 

The question remains: when does this mechanism arise? 

The "direct" observational data are those of the redshift. Beyond that, we reconstruct the situation of the cosmos through a model. If we limit the redshift to the first hundredth of a second, as S. Weinberg did in his book "The First Three Minuts", this physics seems to be known in a satisfactory way. The first confirmation was the discovery of the primitive radiation background, interpreted as resulting from an annihilation between pairs of particles of matter and antimatter. Recalling that until now, the absence of observation of primordial antimatter could not be explained. 

The fact that "all energies are conserved in the phase "with variable constants" would oppose a number of phenomena, such as deionization or others. We can deduce that if this mechanism of drift of constants intervenes it could be before this first hundredth of a second. 

It remains quite problematic to try to give a description of the universe by going further back in time. We only know that the density took extremely high values. When the temperature exceeds 1012° K we consider that the universe would be a mixture of quarks in free state and gluons. A situation that we try to reconstitute in colliders using heavy ions, such as gold or lead. If the theory of considering baryons and mesons as assemblies of quarks has proved to be fruitful, giving rise to the standard model, it remains a model, insofar as it has not been possible to make observations of quarks in the free state. On the other hand, attempts to describe the physical content of higher energies, through the theory of supersymmetry, have not held their promises experimentally. It is perhaps more realistic to admit modestly that we do not really know what happens when we try to go further back in time. 

When we try to create a model of a neutron star we come across problems of a similar nature. When we try to describe the contents of the star, as we go deeper into its entrails, we are led to consider a progressive decomposition of the matter into more and more fundamental components. At the surface of the star: iron plasma, totally ionized. Then, when we go down, the nuclei break up and it is a mixture of electrons and nucleons in the free state. Deeper still, it is the electrons that combine with protons to give neutrons. Electrons that cease to "exist", for lack of space, remembering that their wave function has a spatial extension 1850 times greater than that of neutrons and protons. But the medium still keeps its plasma status, as long as the electric charges of the protons can be neutralized by mesons, whose size is 207 times shorter that the one of electrons. Finally, when it is the mesons' turn to run out of space, the content is described as only formed by neutrons. Finally, when the density increases again, theorists propose a star core constituted by a plasma of quarks and gluons. And in fact this descent to the heart of neutron stars is a way to go back in the past of the universe. 

When the mass of the neutron star increases again, the model proposed by the theorist is the black hole, built from a solution of the field equation referring to a portion of space free of any content. 


18) The question of time. 

In classical chronology, the history of the universe is attached to a time variable t. But what is its physical meaning? How to conceive a clock, on a simple conceptual level, when the different components are animated by thermal agitation speeds that are significantly close to the speed of light. 

One can envisage a kind of conceptual clock constituted by two masses orbiting around a common center of gravity. The most significant way to talk about a time is to link this measurement to an angle. It is the rotation of the second hand on the watch, the period of rotation of the Earth around the Sun, or the rotation of the Milky Way on itself. The measure of time will thus be the measure of a number of revolutions of our elementary clock, by supposing that this one manages to avoid any collision with its surrounding medium, made up of increasingly fast particles. 

In a system where the constants do not vary, this is the case for the masses and the constant G of gravitation. The radius of gyration of the system and the period of rotation are also invariant. In these conditions our elementary clock will count a finite number of revolutions if we go back to a situation where the universe is assimilable to a point. This number of revolutions is then identified with the chosen variable t, which would constitute a good chronological indicator. 


Fig. 17  Horloge élémentaire


It is completely different if we place ourselves in a gauge context, with variable constants. The radius of gyration varies like the space gauge a. The gravitational constant varies as the inverse of a while the masses vary as a. The calculation of the period of the system shows that it varies like the time gauge t, i.e. it is shorter and shorter as we go back in time. The number of revolutions made by our clock is: 

(56)                                              

Thus, from the state, the moment when the spatial extension of the universe will be null until today our clock would total an infinite number of turns. Conversely, to go back to a hypothetical instant zero, in this mode of cosmic evolution, evokes the aphorism of Zeno according to which Achilles, pursuing a tortoise, never manages to catch up with it. 


19) Time or entropy?

The relativistic formulation of the velocity distribution function is 

(57)                              

where m is the rest mass, T the temperature, n the number of density and K2 a Bessel function. If   then we get the classical Maxwell-Boltzmann velocity distribution function : 

(58)                                                   
Let us compute the entropy per baryon, as defined by :

(59)                                         

where k is the Boltzmann’s constant. We have          so that : 

(60)                                                         

The entropy per baryon identifies to the so-called « conformal time ». 





20) Something is always missing. 

The extreme homogeneity of the CMB has led to the proposal of the existence of a fantastic inflation, without any other justification than this single observational data. The model including a "variable constant" step, described by a gauge process, leads to a variable c evolution where the cosmological horizon follows the variation of the space scale factor, which is another way to justify this great homogeneity. But the question to be answered is: 

- What causes this regime change? 

In classical cosmology, and in the phase of the Janus model that follows the decoupling, the masses in the universe do not expand. It is the photons that expand and their wavelength then follows the growth of the space scale factor a. 

We have seen, when we went inside a neutron star, how its content tended to simplify. At the center of the star: neutrons. In order for them to exist, they must be able to install their wave function in the disposable space. The order of magnitude of the minimal space required can be the Comton length of neutrons which is of the order of 10-15 meters. What happens when the density of the medium is such that the average distance between neutrons becomes smaller than this length? There is no clear answer to this question. 

The same question can be asked when we try to retrace the course of events in the universe. If we draw a parallel with the neutron star model, we would be led to consider a medium made up of neutrons and antineutrons, which are more and more closely packed together. A critical moment would then occur, resulting in the transition to a regime of variable constants, where the Compton length of the neutrons ceases to be constant and varies as the space scale factor a. But this is only a conjecture. However, it is not more problematic than the scheme proposed by the inflation theory. We can represent on the figure below the way in which the different constants evolve. On the x-axis, in logarithmic coordinates, a parameter of evolution such as time, the unit value corresponds to the transition between the two regimes. After this time, the constants adopt the values that we know today. If we calculate the Planck length, we notice that it also follows the evolution of the space scale factor, while the Planck time follows that of the time scale factor. 


Fig.18 : Schematic evolution of constants in Log-Log coordinate

21) An alternative interpretation of CMB fluctuations.
In the field equations, the energy-matter content in the form of radiation contributes to the field, as does matter.  In radiative eras these contents are in the majority. 
It is quite legitimate to ask whether a form of gravitational instability could occur in this radiation-dominated medium, in a gas of photons.  Let us suppose that somewhere in the universe there is a region of characteristic dimension L where the content is greater than what is around it. If nothing happens, we can consider that this overdensity of radiation will dissipate in a time L/c. 
If we abandon a lump of material of diameter L to the only forces of gravity it will implode according to a law  or, put differently, this will occur with a characteristic accretion time . By introducing the conservation of mass  we obtain an implosion time (or Jeans time) . 
If now it is a question of an overdensity of radiation this one will create a gravitational field. The evolution of such a cluster will be according to . But as we have then  we will have an implosion time . This overdensity will increase if the dispersion time is greater than the accretion time, i.e. i  ; In other words, the gravitational instability will occur on distance scales greater than
(61)                                                                          
We find then, in this mechanism of a gravitational instability of the photon gas, the equivalent of the Jeans length of the matter. But this one is then of the order of the cosmological horizon. This is the reason why we have never been concerned with a phenomenon which would then be fundamentally unobservable, although it creates fluctuations whose order of magnitude of the wavelength is the Jeans length in the radiative medium. 
These fluctuations being able to occur during the phases of evolution with variable constants, in the two populations, of positive or negative energy, they are not only translated by a fluctuation of but would also affect the values of the constants, with two fields translating variations of the sets: 
(62)                                    
linked by 
(63)   
and : 
(64)                                    
linked by 
 (65)   
We thus see the idea of a multiverse, made up of "universe bubbles" forming a pavement, endowed with their own set of constants, with the corresponding values of the scaling factors. But, unlike what others envisage, the equations would remain the same from one cell to another and, in fact, their histories would not be fundamentally different. All cells of negative energy would give rise, in their dominated matter era, to a regular distribution of spheroidal clusters. In the positive energy cells we would find lacunar structures, giving birth to galaxies and stars. 
But in these sets a difference of their:  . As the Jeans lengths are such that     the spatial distributions of the fluctuations are very different in the two populations. If the negative medium keeps a total homogeneity during its radiative phase, the fluctuations of density of its radiation cause a weak response in the positive world. 
And therein lies, in our opinion, the origin of the fluctuations of the CMB. Their analysis, by identifying the fundamental fluctuation, which is of the order of one degree, gives us access to the relationship:
(62)                                                                  
Since these fluctuations occur as part of the gauge phenomenon, they also affect the values of the physics constants and:
(63)

We also have: 
(64)                                                         
The time of Jeans, in negative masses, is then thousand times shorter than that of positive species. This justifies the scheme of formation of the very large scale structure of the universe, according to which it is the spheroidal clusters of negative mass which are formed first. 
As the thermal agitation viotesses follow the gauge process :   , for numerical simulations of the formation of this very grade scale structure we have the data: 
(65)                                                       

22) The problem of interstellar travel.
The nearest planetary system, linked to the nearest stars, is four light years away. This fact made that until now it was considered that the idea of being able one day to realize trips towards these close systems would be unthinkable at the scale of a human vacuum. But the new geometric context changes things. The universe is a variety equipped with two different metrics. All the points of the variety are located with the help of dimensionless dcoordinates: 
(66)                                                               
Let two points A and B be distant, with coordinates 
(67)                                           
The distance between these two points will be different depending on whether it is covered in the positive or negative mass sector: 
(68)                         
If a vehicle had a technology allowing it to reverse its mass (and that of its passengers) the distance it would have to cover would be a hundred times shorter. Moreover the speed limit, at that of the light in the negative sector, would be raised of a factor ten. From where a priori a weaker travel time of three orders of magnitude. 
Thus interstellar travel becomes non-impossible.
Once arrived at its destination, the vehicle would only have to operate a new mass inversion to find itself in the positive sector. During its journey, the passengers of this vehicle would lose all possibility of having observations of the positive mass environment, always present but now invisible to it. Inversely, they would be the spectators of the negative world scenery, that is to say, they would be able to see the spheroidal clusters of negative mass, emitting in the red and the infrared. 
At the moment of the mass inversion two equivalent volumes, positive and negative sectors would be exchanged. If the vehicle performs its mass inversion when it is in the atmosphere, it will no longer be visible to observers made up of positive mass and will seem to dematerialize in their eyes. 
As the negative sector, in the solar system, is ultra rarefied, the content of the equivalent volume which will take the place of the one occupied by the vehicle will be filled with photons and very rare atoms of anti-hydrogen and anti-helium whose masses, having also undergone an inversion, became positive and will annihilate in contact with the atoms and molecules of the atmosphere, by producing gamma rays. The irruption of the air molecules in a space perceived as quasi empty will produce a disturbance of aerodynamic nature. 
This process of mass inversion is equivalent to swapping adjacent contents located on the front and back of the hypersurface. It is thus a problem of topology. For there to be historical continuity it is necessary that the vehicle and its passengers follow a continuous line of universe, continuing their progression towards the future. The fact of momentarily moving in the negative sector does not mean that the passengers would see their own time reversed, that is to say that they would not reappear in their own past. This path would make them cross on their way the small quantity of antimatter present in the negative sector, endowed then with the same sign of the mass. Of which the vehicle and this antimatter could interact. But the vehicle could then protect itself from this flow of antimatter, comparable to the solaore wind emitted by the sun, from which the Earth protects itself with the shield constituted by its magnetic field. 

23) The problem of swapping volumes between adjacent sectors. 
A first scheme of mass inversion has been evoked in the article [29], through a reinterpretation of the Schwarzschild solution of the Einstein equation.


According to the scheme of special relativity the energy equivalent to a mass M is Mc2. If the amount of energy needed to invert this mass was of this order, this technology would be problematic. We are faced with the problem of swapping two adjacent volumes of 4D hypersurfaces. It is convenient to consider the positive and negative sectors as a kind of "parallel universe". But the picture is immediately misleading because one can hardly take into account the considerable difference between scale factors a(+) and a(-). If we disregard this, we can give a 2D image of these two folds by simply representing them by two parallel planes.

Fig.19 : Before surgery
The alteration that we consider to give to these two folds is a local variation of the curvature, equivalent to a local concentration of energy. We will present a solution referring to a 2D toy model, where the permutation of two adjacent domains, whose borders are cerce, is operated by an operation described in topoogy by the word surgery. 
A technological device causes a concentration of positive energy, in the positive sector, in the external vicinity of the wall. This is shown in this sequence of didactic images, by a kind of groove. We then split the object by presenting only half of it in order to perceive the curvature given to the surfaces. We suppose that the alteration of the curvature, in the upper fold, supposed to translate a concentration of energy, would cause a "curvature induced" in the adjacent fold. 

Fig.20 : Preparation of the surgery


Fig.21 : The surgery occurs along a circle

The geometrical operation of surgery involves the creation of an infinite curvature along a circle. In the field of physics this could be a very pronounced curvature, associated with a very high local density of energy. It is necessary to understand that when this one is operated the adjacent parts of folds 1 and 2 have been exchanged. 

Fig.22 : The exchanged portions

This is equivalent to :

Fig 23 : After surgery

To illustrate the suggested scheme we represent the reduction of the grey portion:

Fig 24 : disappearance of the portion from fold 2

This is only a toy model. This said, techniques to concentrate energy in a region of space forming a thin layer can be envisaged, for example by imparting energy to nuclei possessing a long-lived metastable excitation level, as we know they exist.. 

24) Gravitational lens effect created by a gap in the negative mass.
One can obviously reason that the gravitational field created by a negative mass is equivalent to a positive mass distrubution, by inverting the masses. But this needs to be justified. Indeed one would tend to think that the examination of such a configuration could be done from the Poisson equation. But let's see what it is. Let us consider a distribution of any density and a spheroidal gap in the sense of this distribution. The Poisson equation being linear we are tempted to say that this configuration results from the superposition of a distribution with a uniform density , to which we superimpose the field created by a sphere filled with a uniform density  .
When we calculate the gravitational field present in a uniform distribution of matter we see a paradox appear. It is non-zero and its intensity increases proportionally to the distance to a point arbitrarily chosen as the origin of the radial coordinate r  
(69)                                                     
Solution : 
(70)                                        
The field in the density sphere is inverted. So the sum of the two gives zero. We conclude that if we base ourselves on the Poisson equation, the field inside a gap is zero. 
We must consider the origin of the Poisson equation. For a finite distribution of matter, in space, we can use Green's theorem to calculate the flow through a closed surface of a force derived from a Newtonian force. The Poisson equation of the gravitational potential  is then similar to that referring to the electric potential. There is a change of sign related to the fact that a positive electric charge creates a field which repels a test particle of electric charge +1 while a positive mass attracts a test mass of mass +1. 
But we can no longer extend this mode of construction for an infinite mass distribution. 
We must then start from the Poisson equation as a linearized form of the field equation. Let's see how the calculation is conducted [30]  .
By neglecting the speed before c the matter energy tensor is written :
 (71)                                                
Classically one assumes the flow to be stationnary and therefore the metric to be time-independant. Using the coordinates of special relaticity   ct , y , y and z , one considers a time-independent metric which is the sum of the Lorentz metric and a small time- independant perturbation   . 
(72)                                                              
If we neglect the term of the order of   , the Laue scalar   is 
(72)                                                 
and the right side of the field equation is to the first order in smal quantities  : 
(73)

Neglecting the second-order terms in  gives the following approximate form for the contracted Riemann tensor :
(74)                                      
Consider first the case  . Since we are considering a rim-independent metric, the first term of (74) is zero, so we are left with the equation 
(75)                                          
The Christoffel symbol of the first kind is defined by 
(76)                                                
Since the Lorentz metric is constant in space and time, this simplifies to 
(77)                                                               
Furthermore  is time-independent, so  is zero. Neglecting the second-order terms in , we then have
(78)                                                          
which is zero for  . 
Substituing in (75) we obtain an approximate field equation for   
(79)                                                                  
or, by virtue of time independence, 
(80)                                                                
This makes it possible to show a gravitational potential according to  
(81)                                                                  
By opting for the definition of the Einstein constant according to : 
(82)                                                                      
We obtain the Poisson equation. 
(83)                                                                  
But, in this approach, it should be noted that everything is based on the fact that we can consider a stationary metric solution, in the zero order, expressed in the form of a Lorentz metric , immediately associated to a portion of empty space.  In the above, the perturbation of the metric is due to a density of finite extension. It is not possible to reconcile this approach on the basis of a non-empty, uniform and infinite density of order zero. 

The conclusion is that it is simply impossible to define 
a gravitational potential in a uniform matter distribution.

 The Poisson equation cannot be used. In such a medium the mass points are attracted in the same way in all directions and the resultant of this force is zero. The solution (70) is therefore not physical. 

The corollary is that the gravitational field associated with a gap in a uniform dustribution of matter, whether this mass is positive or negative, is equivaent to the field created by : 

- A uniform distribution of density   

- The image of the gap with  changed sign, corresponding to a density , inverted. 


Conclusion: a gap in a negative mass distribution: 

- Allows to confine the galaxy lodged in this lacuna

- Produces a positive gravitational lensing effect, which then gives the impression that it is due to a dark matter of positive mass

25) Interpretation of the Great Repeller phenomenon.
There is no attempt in the literature to give a theoretical interpretation of the Great Repeller phenomenon, discovered in 2017 [7]. In conferences, some astrophysicists simply say that this phenomenon could be created by a gap in the field of dark matter, of positive mass. As they know the paradox related to the Poisson equation, but do not know how to deal with it, their relarques stop there. There is a change of sign because, with respect to a control electric charge +1 a positive charge creates a Newtonian force of repulsion, whereas with respect to a control mass +1 a positive mass creates an attractive Newtonian force. This equation is obtained by evaluating the flux of the electric field vector across a closed surface and applying Green's theorem. But nobody would consider a world where the electric charge would not be zero at infinity. 
In gravitation we will be forced to consider the Poisson equation as the linearized version of Einstein's equation in a very restrictive case: in a stationary (or quasi-stationary) situation and when we can describe the metric as a perturbation of a Lorentz metric Definitively, the Janus model is the only one that provides a coherent interpretation of this phenomenon.

26) – Conclusion
This work suggests a complete upheaval of cosmology, as well as an extension of theoretical physics to the field of negative energies. It is a real paradigm shift. As it stands, the negative mass model provides a credible cosmological alternative and quantum mechanical framework to dark energy/dark mass conjectures. For such a model to impose itself, it is not enough to propose alternative interpretations to those attributed to dark matter and dark energy. It will have to provide answers to all the questions in order to be able to pose as a challenger of the ΛCDM model, a standard model that we should call i-ΛCDM insofar as this last implies an additional hypothesis, that of the existence of a field of inflatons, responsible for the phenomenon of cosmic inflation, a hypothesis whose only merit is to justify the extreme homogeneity of the primitive universe. If it does not resort to this phenomenon of cosmic inflation, the new model will therefore have to produce something that alternatively accounts for this homogeneity. In addition, it will have to provide its own model of the fluctuations of the CMB. Finally, it will have to provide the reason why, at the end of its radiative phase, these two sets of masses, positive and negative, obey the same equations, equipped with different sets of constants.. 
The answers to these questions will be outlined in the following article. 

References : 
[1]  Rubin v.c. Ford w.k , Thonnard N.  « Rotational velocities of 21 SC galaxies with large luminosities and radii ». Apj. 1980 238 pp 471-487
[2]   M.Milgrom : « A modification of the Newtonian dynamics as a possible alternative to the hidden mass hypothesis ». Astrophysical Journal, Part 1 (ISSN 0004-637X), vol. 270, July 15, 1983, p. 365-370.
 [3] Perlmutter, S., et al.  1999, ApJ, 517, 565

[4] Riess A. G. 2000, PASP, 112, 1284

[5] Schmidt, B. P., et al., 1998, Astrophys. J. 507, 46.

 [6]   N.Debergh, J.P.Petit and G.D’Agostini : Evidence of negative energies and masses in the Dirac equation through a unitary time-reversal operator. , J. Phys. Comm. 2 (2018) 115012   http://iopscience.iop.org/article/10.1088/2399-6528/aaedcc/pdf
 [7]   The Dipole Repeller : Y. Hoffman, D.Pomarède, R.B.Tully, H.Courtois. Nature Astronomy 2017 1 , 0036  
 [8]   Bondi H. : Negative mass in General Relativity. Rev. of Mod. Phys., Vol 29, N°3, july1957

 [9]    Bonnor W. B. : Negative mass and general relativity. General Relativity and Gravitation Vol. 21, N°11, 1989 

 [10]   A. Benoit-Lévy & G.Chardin : Introducing the Dirac-Milne universe. Astronomy and Astrophysics. Vol. 537 (january 2012) A 78

 [11]   J.Farnes : A unifying theory of dark energy ans dark matter : Negative mass and matter creation within a modified LCDM framework. Astronomy ans Asntrophysics 2018

 [12]   J.P.Petit, Twin Universe Cosmology, Astrophys. and Sp. Science, 226, 273-307, 1995

 [13]   J.P.Petit : The missing mass problem. Il Nuovo Cimento B Vol. 109 July 1994, pp. 697-710
 [14]    J.P.Petit, G.D’Agostini : Negative Mass hypothesis in cosmology and the nature of dark energy. Astrophysics And Space Science,. A 29, 145-182 (2014)

 [15]   J.P.Petit & G.D’Agostini : Lagrangian derivation of the two coupled field equations in the Janus Cosmological Model. Astrophysics and Space Science 2015, 357 :67

 [16]   S. Hossenfelder : A bimetric Theory with Exchange Symmetry. Phys. Rev. D78, 044015, 2008 and arXiv : 0807.2838v1 (gr-qc)17 july 2008 

[17]   Damour T. , Kogan I I. Effective Lagrangians and universality classes of nonlinear bigravity Phys. Rev. D 66 (2002) 104024. hep‐th/0206042. 

 [18]   Damour T. , Kogan I. I. , Papazoglou A. Non‐linear bigravity and cosmic acceleration Phys. Rev. D 66 (2002) 104025. hep‐th/0206044. 

 [19]   G. DAgostini and J.P.Petit : Constraints on Janus Cosmological model from recent observations of supernovae type Ia, Astrophysics and Space Science, (2018), 363:139.https://doi.org/10.1007/s10509-018-3365-3
 [20]   S.Chandrasekhar : « Principles of stellar dynamics » Dover Publications 1942
 [21]   S.Chapman and T.G.Cowling : « The mathematical theory of non uniform gases. Cambridge University press ? 
 [22]  J.P.Petit et G.Monnet : » Axisymmetrical solution of the couple Vlasov plus Poisson equations ». CNRS 1974 meeting on the dynamic of spiral galaxies. Institute of High Scientific Studies (IHES).  

 [23]  J. P. Petit, P. Midy and F. Landhseat (pseudonym for F.Descamp), Twin matter against dark matter, int. Conf. onAstrophysics and Cosmology, Where is the Matter?, Tracing Bright and Dark Matter with the New Generation of Large-Scale Surveys (Marseille, France, June 2001).
 [24]  A.D.Sakharov , (1980). Cosmological Model of the Universe with a Time Vector Inversion. ZhETF (Tr. JETP 52, 349-351) (79): 689–693

 [25]  J.M.Souriau : Structure des systèmes dynamiques.  Dunod Ed. France, 1970 and Structure of Dynamical Systems. Boston, Birkhaüser Ed. 1997

 [26]  S.Weinberg : The Quantum Theory of Fields I . Cambridge University Press 2005

[27]  J.P.Petit : Cosmological model with variable velocity of light. Modern Phys Letters A3, 1988, pp. 1527

[28]  J.P.PETIT  : Cosmological model with variable velocity of light. The interpretation of redshifts. Col.3 n° 88 (1988) 1733-1744. 

[29]  J.P.Petit & G.D’Agostini : Cancellation of the singularity of the Schwarzschild solution with natural mass inversion process. Mod. Phys. Lett. A vol. 30 n°9  2015
In arXiv (gr-qc) : https://arxiv.org/abs/2103.12845
[30]  R.Adler, M.Schiffer, M Bazin Introdution to general relativity.  Mc Graw Hill book company 1975

__________________________________________________________________________________
Appendix 1
Compatibility conditions
The equations are: 
(a)                                     


(b)                                


(c)                                     

(d)                                 

A linear combination of  (a) and (b) gives : 
(e)                                 
Anothe one : 


(f)               


We differentiate (a) with respect to  t :

(g)        

combining to (f) : 

(h)                   

ou 
(i)                                  
Treating equations (27) and (28) in the same way we obtain  : 

(j)                                    

___________________________________________________________________________________

Appendix II
Calculation of the group's action on its space of moments.
The group is represented by the matrices:
(a)                                      
For convenience of calculation we will carry out this one with 
(b)                                        
The element of its Lie algebra is then: 
(c)                                                    
The group is differentiated in the vicinity of its neutral element. Under these conditions can be put in the form where G is the Gramm matrix and  an antisymmetric matrix
(d)                                            
For computational convenience, we write the action of the group on its Lie algebra  instead of  , which is equivalent to computing the action of the inverse of the element of the group on the element of its Lie algebra, but the result will be equivalent since the set of inverses also represents the group. It comes : 
(e)                         
which gives : 
(f)
 

We are looking for the dual of the group's action on its Lie algebra. The element of this Lie algebra depends on 11 parameters. 

(g)                            
The moment space of the group will thus be a vector space of dimension 11. It can be put in the form of an antisymmetric matrix M of format (4,4), depending on six parameters, a quadrivector P and a scalar q. The duality can thus be ensured by the constancy of the scalar:
(h)                                                    
which gives:
(i)   
It comes immediately: 
(j)                                                                 
 (k)                                              

We know that we can perform a circular permutation in the trace: 

(l)                                           

The identification on the  terms gives

(m)                                        
The term  is the scalar product of the row vector by the column vector . We can therefore write, after having performed a circular permutation in the trace
 (n)                                                
By making a circular permutation in the trace. Thus the equation (m) provides: 
(o)                                                          
But 
(p)                                     
Knowing that the trace of the product of a symmetrical matrix by an antisymmetrical matrix is equal to zero: 
(q)                                                 
It remains: 
(r)                    
Which provides the last equation of the group's action on its moment:
(s)                                             
We make the inversion parameter reappear by  and group the results together

 (t)                                                                 
(u)                                                 
(v)                                                                     
P is the energy-impulsions 4-vector : 
(w)                                                                                                       
Equations (t),(u),(v) represent an extension of equations 13.107 of reference [27]. The relation (v) makes it possible to find Souriau's relation ([27] page 190, equations 14.67 ). The inversion of time  leads to the inversion of energy and of the impulse vector  . The matrix M depending on six parameters can be decomposed into two vectors. The vector f is what Souriau calls the passage and s is the spin.
 (x)                                              
The passage f is not an intrinsic attribute of the motion because it can be cancelled by a change of variable accompanying the particle. Only the spin remains, of which Souriau demonstrated in 1970 its geometrical nature. By cancelling the spatio-temporal translation C the relation (u), where   does not appear, shows that the inversion of time does not modify the spin vector. With this way of carrying out the calculation one obtains the result of the action of the group on a movement, characterized by the quantities gives another movement . It is the relation (t) which informs on the fact that starting from a motion representing that of a particle of matter : 
- results in a PT-symmetry plus a C-symmetry . One thus obtains the movement of a particle of negative mass. 
- operates a C-symmetry. The movement obtained is that of an antiparticle in the sense of Dirac, of positive mass. 
- represents a PT-symmetry. The motion is that of an antiparticle of negative mass (antiparticle in the sense of Feynmann). 
___________________________________________________________________________________

Appendix III

Construction of generalized gauge relations
We will assume tht during the radiation dominated era all forms of energy are conserved, including the energy of the photons. Let a be the space scale factor. This hypothesis will give a single universal gauge relationship :
 (1)

Let’s write the metric : 
(2)

where 
(3)

is the Lorentzian metric.
 is a scale factor. is a conformal metric :
(4)

We shall assume that the scale facor  will rule all the evolution process in radiation dominated era. Angles are conserved. Lenghts vary like a. Energies are conserved. 
   is a length. We may introduce some cosmic time and speed of light, writing the metric : 
(5)

Let’s introduce variable speed of light 
(6)

Introduce a time scale, through  : 
(7)

Then : 
(8)

 are adimensional quantities, which are not involved in the gauge process.  Lorentz invariance is ensured if : 
(9)

The constants of physics are : 
(10)

Let’s express all those « constants » of physics, introducing the following adimensional forms :
(11)

(12)

(13)

(14)

(15)

(16)

Write the conservation of energies : 
(17)

(18)

The conservation of the gravitational energy  gives : 
(19)

From (1)
(20)

Express gauge invariance of the Schwarzschild’s length :
(21)

Introduce gauge invariance of Kepler’s law :
 (22)

We get : 
(23)

and : 
(24)

(25)

Assume that the number of species is conserved : 
(26)

By the way the Planck’s length is also gauge invariant : 
(27)

whence : 
(28)


Express the gauge invariance of Bohr’s radius : 
(29)

Express the gauge invariance of any atomic structure. The fine constant must be an absolute constant, and 
(30)

As : 
(31)

Assuming conservation of charged species :
(32)

Express that the electromagnetic energy is constant, gauge invariant. 
(33)

(34)

The gauge invariance of kinetic energy ( and relativistic energy)  gives : 
(35)

In this gauge process the so called constants of physics are no longer absolutely constant. The following quantities are involved in an universal generalized gauge process : 
(36)

We can express any set of seven of those quantities and  express their variation with respect to the eigth. 

Generalized gauge invariance of the equations of physics
We can now show that all equations of physics are gauge-invariant with respect to this generalized gauge variation law. 
Consider Maxwell equations : 
(37)

is gauge-invariant because : 
(38)

Obviously    is gauge-invariant. 
Electron-electron collision cross section is : 
(39)


(we can check that the Debye’s length  . In general, all physical lengths of physics, like Jeans ‘ Length, vary like a, while all characteristic times, like Jeans’ time or Planck’s time,  vary like t*). 
(40)

The invariance of : 
(41)

is ensured. Same thing for Poisson equation
 (42)

Shifting to General relativity formalism we can check that the field equation is also gauge-invariant. 
(43)


It depends how we define the Einstein’s constant. In old book where we write : 
(44)


Todays, we find in litterature : 
(45)

Anyway : 
(46)

Of course the Poisson equation invariance is obviously ensured, for it is nothing but the Newtonian approximation of the above field equation. 
The gauge invariance of  Schrödinger equation is ensured too  : 
(47)

goes with : 
(48)

Let us check Boltzmann equation : 
(49)

From Boltzmann equation we can derive Navier-Stockes’ equations, applying to all kinds of fluids, including plasmas. With a zero second membre it becomes Vlasov equation. Coupled to Poisson and applying to self-gravitating sets of mass points it is the key for understanding galactic dynamics. 
Introducing adimensional form   for the distribution of velocities : 
(50)

(51)

The equation, written into adimensional form, becomes : 
(52)

whence : 
(53)

By the way, all pressures are energy densities. As energy is conserved in our model we have : 
(54)

We have shown that all equations of physics fit our generalized gauge relationship system. Conversely, we could build it, searching invariance properties of this set of equations. 
This gauge process cannot fits matter dominated era. In effect, if photon’s energy is conserved no redshift would be observed, so that we suggest that such generalized gauge process would only refer to radiation dominated era.  Some transition would occur. Then in this new regime  behave like absolute contsants. 
During the « variable constants » era the definition of the cosmic time is somewhat delicate. Right now, as a convenient time-marker let’s take  so that we have : 
(55)

In addition : 
(56)

___________________________________________________________________________________